# PAW Configuration
# This file controls PAW's behavior. Environment variables override these values.

# --- LLM ---
llm:
  model: "openai/gpt-4o-mini"    # LiteLLM model identifier (e.g., anthropic/claude-3-5-sonnet, ollama/llama3)
  smart_model: "openai/gpt-5.3-codex"
  temperature: 0.7
  max_tokens: 4096
  fallback_models:                # Models to try if primary fails
    # - "anthropic/claude-3-5-sonnet"

# --- Agent ---
agent:
  max_iterations: 10              # Max ReAct loop iterations per request
  max_tool_calls: 20              # Max tool calls per request
  token_budget: 100000            # Max tokens per request
  daily_token_budget: 1000000     # Daily token limit

# --- Shell ---
shell:
  enabled: true
  timeout: 30                     # Command timeout in seconds
  blocked_commands:               # Always blocked
    - reboot
    - shutdown
    - init
    - mkfs
  approval_patterns:              # Blocked patterns requiring explicit review before use
    - "rm -rf"
    - "dd "
    - "sudo"
  writable_dirs:
    - /home/paw/workspace
    - /home/paw/plugins
    - /home/paw/data
    - /tmp

# --- Server ---
host: "127.0.0.1"
port: 8000
log_level: "INFO"
log_format: "json"               # "json" or "console"

# --- Channels ---
channels:
  telegram:
    enabled: false
    mode: "polling"               # "polling" or "webhook" (webhook planned next phase)
    dm_policy: "allowlist"        # "allowlist" | "open" | "disabled"
    allow_from: []                 # Telegram user IDs as strings, e.g. ["12345678"]
    groups_enabled: false
    require_mention: true
    agent_mode: true
    # model: "openai/gpt-4o-mini"         # Optional Telegram-specific regular model override
    # smart_model: "openai/gpt-5.3-codex" # Optional Telegram-specific smart model override
    poll_timeout_s: 25
    retry_delay_s: 3
    max_message_chars: 3500
